id: sglang-deepseek
base_config:
  model: deepseek-ai/DeepSeek-V3.1
  data:
    - prompt_tokens=128,output_tokens=1024
    - prompt_tokens=1024,output_tokens=128
    - prompt_tokens=512,output_tokens=512
    - prompt_tokens=256,output_tokens=2048
    - prompt_tokens=2048,output_tokens=256
    - prompt_tokens=1024,output_tokens=1024
    - prompt_tokens=512,output_tokens=4096
    - prompt_tokens=4096,output_tokens=512
    - prompt_tokens=2048,output_tokens=2048
  llm_server_type: sglang
  llm_server_config:
    extra_args: ["--tp", "8", "--context-length", "16384"]
configs:
  - gpu: H200:8
    region: us-east-1
  - gpu: B200:8
    server_region: us-ashburn-1
    client_region: us-east-1
    llm_server_config:
      extra_args: ["--tp", "8", "--context-length", "16384"]
      version: v0.4.10.post2-cu128-b200
